{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用TensorFlow實作圖片分類\n",
    "卷積神經網絡（Convolutional Neural Network, CNN）是一種前饋神經網絡，它的人工神經元可以響應一部分覆蓋範圍內的周圍單元，對於大型圖像處理有出色表現。\n",
    "<img src=\"img/network.png\" width=\"600px\" />\n",
    "卷積神經網絡由一個或多個卷積層(convolutions layer)和頂端的全連通層（對應經典的神經網絡）組成，同時也包括關聯權重和池化層（pooling layer）。這一結構使得卷積神經網絡能夠利用輸入數據的二維結構。與其他深度學習結構相比，卷積神經網絡在圖像和語音識別方面能夠給出更好的結果。這一模型也可以使用反向傳播算法進行訓練。<br><br>\n",
    "## 卷積層(convolutions layer)\n",
    "卷積層就像一台掃模器，一次掃較小的圖塊，掃出來的結果就會是更高維度、大小更小的照片集，如下圖所示。\n",
    "<img src=\"img/CNN架構.jpg\" width=\"600px\" /><br>\n",
    "<img src=\"img/convolutions_2.jpg\" width=\"400px\" /><br>\n",
    "<img src=\"img/convolutions.jpg\" width=\"400px\" /><br>\n",
    "## 池化層(pooling layer)\n",
    "池化層是卷積神經網絡中另一個重要的概念，它實際上是一種形式的降採樣。有多種不同形式的非線性池化函數，而其中「最大池化（Max pooling）」是最為常見的。它是將輸入的圖像劃分為若干個矩形區域，對每個子區域輸出最大值。直覺上，這種機制能夠有效地原因在於，在發現一個特徵之後，它的精確位置遠不及它和其他特徵的相對位置的關係重要。池化層會不斷地減小數據的空間大小，因此參數的數量和計算量也會下降，這在一定程度上也控制了過擬合。通常來說，CNN的卷積層之間都會周期性地插入池化層。<br>\n",
    "\n",
    "池化層通常會分別作用於每個輸入的特徵並減小其大小。目前最常用形式的池化層是每隔2個元素從圖像劃分出2*2的區塊，然後對每個區塊中的4個數取最大值。這將會減少75%的數據量。<br>\n",
    "<img src=\"img/pool.jpg\" width=\"400px\" />\n",
    "<img src=\"img/pool_2.jpg\" width=\"400px\" /><br>\n",
    "經過數個卷積層和池化層後，剩下的就是一塊一塊小圖片，並且厚度會逐漸加厚(圖片數量變多)，那麼這些小圖片就是CNN network抽取出來的特徵，將這些特徵再往下接到MLP network(hidden layer)，最後分成數個類別，再輸出層(output layer)，假設我要分成10個種類，那最後10個layer分別會帶有不同的數字(這些數字加總為1)，代表模組經過學習後，認為這張圖片為哪項分類的機率，而我們當然是選擇機率最大的為最後分類結果(softmax)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義畫圖funtion\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_images_labels_predict(images, labels, prediction, idx, num=25):  \n",
    "    fig = plt.gcf()  \n",
    "    fig.set_size_inches(12, 14)\n",
    "    if num > 25: num = 25  \n",
    "    for i in range(0, num):  \n",
    "        ax=plt.subplot(5,5, 1+i)  \n",
    "        ax.imshow(images[idx], cmap='binary')  \n",
    "        title = \"lable=\" + str(labels[idx])  \n",
    "        if len(prediction) > 0:  \n",
    "            title = \"lable={},prediction={}\".format(str(labels[idx]), str(prediction[idx]))  \n",
    "        else:  \n",
    "            title = \"lable={}\".format(str(labels[idx])) \n",
    "        ax.set_title(title, fontsize=10)  \n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        idx+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>street</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forest</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tallbuilding</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PARoffice</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>industrial</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     folder_name  label\n",
       "13        street      1\n",
       "4         forest      4\n",
       "14  tallbuilding     13\n",
       "1      PARoffice      7\n",
       "6     industrial      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#讀取mapping並寫入data frame裡，方便後續做分類、抓取資料\n",
    "mapping_df = pd.read_csv('//data/examples/may_the_4_be_with_u/where_am_i/mid_term_mapping.txt' ,header=None)\n",
    "mapping_df.columns = ['folder_name', 'label']\n",
    "mapping_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "test_submit_df = pd.read_csv('//data/examples/may_the_4_be_with_u/where_am_i/img-submission.csv')\n",
    "#test_submit_df.columns = ['file_name', 'label']\n",
    "print(len(test_submit_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_name</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>street</td>\n",
       "      <td>1.0</td>\n",
       "      <td>//data/examples/may_the_4_be_with_u/where_am_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>opencountry</td>\n",
       "      <td>6.0</td>\n",
       "      <td>//data/examples/may_the_4_be_with_u/where_am_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>CALsuburb</td>\n",
       "      <td>9.0</td>\n",
       "      <td>//data/examples/may_the_4_be_with_u/where_am_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>industrial</td>\n",
       "      <td>2.0</td>\n",
       "      <td>//data/examples/may_the_4_be_with_u/where_am_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>opencountry</td>\n",
       "      <td>6.0</td>\n",
       "      <td>//data/examples/may_the_4_be_with_u/where_am_i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      folder_name  label                                               path\n",
       "2603       street    1.0  //data/examples/may_the_4_be_with_u/where_am_i...\n",
       "2169  opencountry    6.0  //data/examples/may_the_4_be_with_u/where_am_i...\n",
       "77      CALsuburb    9.0  //data/examples/may_the_4_be_with_u/where_am_i...\n",
       "1101   industrial    2.0  //data/examples/may_the_4_be_with_u/where_am_i...\n",
       "2219  opencountry    6.0  //data/examples/may_the_4_be_with_u/where_am_i..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#所有的照片已經預先分類在15個資料夾中，所以透過mapping_df[folder_name]，我們可以造訪所有的train data並記下每張圖片的路徑\n",
    "import os\n",
    "image_mapping_path_df = pd.DataFrame(columns=['folder_name', 'label', 'path'])\n",
    "path = \"//data/examples/may_the_4_be_with_u/where_am_i/\"\n",
    "pathData = []\n",
    "for x in range(0, len(mapping_df['folder_name'])):\n",
    "    folder_name = mapping_df['folder_name'][x]\n",
    "    label = mapping_df['label'][x]\n",
    "    class_folder = path + \"train/\" + folder_name\n",
    "    for train_imgName in os.listdir(class_folder):\n",
    "        train_data_path = class_folder + \"/\" + train_imgName\n",
    "        s = pd.DataFrame([[folder_name, label, train_data_path]],columns=['folder_name', 'label', 'path'])\n",
    "        image_mapping_path_df = image_mapping_path_df.append(s, ignore_index=True)\n",
    "image_mapping_path_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2984/2984 [04:57<00:00, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Info] Shape of train data=(2985, 256, 256, 3)\n",
      "\t[Info] Shape of train label=(2985,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#接著利用剛剛記下的路徑，抓取每張圖片，並設定大小\n",
    "image_width = 256\n",
    "image_high = 256\n",
    "#image_cnn_shape是我在cnn層最後每張圖片的大小，因為總共做了4次 pool每次都取2*2，所以長、寬分別剩下1/16\n",
    "#image_cnn_shape = (image_width//16) * (image_high//16)\n",
    "image = cv2.imread(image_mapping_path_df[\"path\"][0])\n",
    "image = cv2.resize(image, (image_width, image_high))\n",
    "#image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#train = np.reshape(image, (32, 32))\n",
    "train = np.expand_dims(image, axis=0)\n",
    "#train = np.reshape(image, (1, 262, 200))\n",
    "train_label = np.zeros(0, dtype=float)\n",
    "train_label = np.append(train_label, image_mapping_path_df[\"label\"][0])\n",
    "for x in tqdm(range(1, len(image_mapping_path_df))):\n",
    "    path = image_mapping_path_df[\"path\"][x]\n",
    "    label = image_mapping_path_df[\"label\"][x]\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (image_width, image_high))\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #train = np.reshape(image, (32, 32))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    train = np.concatenate((train,image), axis=0)\n",
    "    train_label = np.append(train_label, label)\n",
    "\n",
    "print(\"\\t[Info] Shape of train data=%s\" % (str(train.shape)))\n",
    "print(\"\\t[Info] Shape of train label=%s\" % (str(train_label.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_TrainOneHot.shape =  (2985, 15)\n",
      "9.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "         0.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_TrainOneHot = np_utils.to_categorical(train_label) # 將 training 的 label 進行 one-hot encoding\n",
    "print(\"y_TrainOneHot.shape = \",y_TrainOneHot.shape)\n",
    "print(train_label[0]) # 檢視 training labels 第一個 label 的值\n",
    "y_TrainOneHot[:1] # 檢視第一個 label 在 one-hot encoding 後的結果, 會在第10個位置上為 1, 其他位置上為 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 切割資料集\n",
    "把原本的train data切割成train 跟 valid兩塊<br>\n",
    "train data用來訓練模組 而 valid data用來檢視模組學習成效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: 2388\n",
      "test set: 597\n"
     ]
    }
   ],
   "source": [
    "#----------------------------資料training set, testing set 分割---------------------------------------\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train,\n",
    "                                                    y_TrainOneHot,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    stratify  = y_TrainOneHot.argmax(axis = 1))\n",
    "print(\"training set: %i\" % len(x_train))\n",
    "print(\"test set: %i\" % len(x_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 數據增強(ImageDataGenerator)\n",
    "在train data數量不足時，可以透過數據增強的方式，生成新的數據。<br>\n",
    "數據增強有很多種方式，例如:選轉圖片、翻轉圖片、將圖片比例縮放、白化、平行拉長...<br>\n",
    "這邊我實作時，用的是keras的API，在下面附上所有參數。<br>\n",
    "featurewise_center：布尔值，使输入数据集去中心化（均值为0）, 按feature执行\n",
    "\n",
    "samplewise_center：布尔值，使输入数据的每个样本均值为0\n",
    "\n",
    "featurewise_std_normalization：布尔值，将输入除以数据集的标准差以完成标准化, 按feature执行\n",
    "\n",
    "samplewise_std_normalization：布尔值，将输入的每个样本除以其自身的标准差\n",
    "\n",
    "zca_whitening：布尔值，对输入数据施加ZCA白化\n",
    "\n",
    "zca_epsilon: ZCA使用的eposilon，默认1e-6\n",
    "\n",
    "rotation_range：整数，数据提升时图片随机转动的角度\n",
    "\n",
    "width_shift_range：浮点数，图片宽度的某个比例，数据提升时图片水平偏移的幅度\n",
    "\n",
    "height_shift_range：浮点数，图片高度的某个比例，数据提升时图片竖直偏移的幅度\n",
    "\n",
    "shear_range：浮点数，剪切强度（逆时针方向的剪切变换角度）\n",
    "\n",
    "zoom_range：浮点数或形如[lower,upper]的列表，随机缩放的幅度，若为浮点数，则相当于[lower,upper] = [1 - zoom_range, 1+zoom_range]\n",
    "\n",
    "channel_shift_range：浮点数，随机通道偏移的幅度\n",
    "\n",
    "fill_mode：；‘constant’，‘nearest’，‘reflect’或‘wrap’之一，当进行变换时超出边界的点将根据本参数给定的方法进行处理\n",
    "\n",
    "cval：浮点数或整数，当fill_mode=constant时，指定要向超出边界的点填充的值\n",
    "\n",
    "horizontal_flip：布尔值，进行随机水平翻转\n",
    "\n",
    "vertical_flip：布尔值，进行随机竖直翻转\n",
    "\n",
    "rescale: 重放缩因子,默认为None. 如果为None或0则不进行放缩,否则会将该数值乘到数据上(在应用其他变换之前)\n",
    "\n",
    "preprocessing_function: 将被应用于每个输入的函数。该函数将在图片缩放和数据提升之后运行。该函数接受一个参数，为一张图片（秩为3的numpy array），并且输出一个具有相同shape的numpy array\n",
    "\n",
    "data_format：字符串，“channel_first”或“channel_last”之一，代表图像的通道维的位置。该参数是Keras 1.x中的image_dim_ordering，“channel_last”对应原本的“tf”，“channel_first”对应原本的“th”。以128x128的RGB图像为例，“channel_first”应将数据组织为（3,128,128），而“channel_last”应将数据组织为（128,128,3）。该参数的默认值是~/.keras/keras.json中设置的值，若从未设置过，则为“channel_last”\n",
    "<br>\n",
    "參考資料:https://keras-cn.readthedocs.io/en/latest/preprocessing/image/<br>\n",
    "        https://zhuanlan.zhihu.com/p/30197320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Gene epochs = 0\n",
      "Data Gene epochs = 1\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,\n",
    "    samplewise_center = False,\n",
    "    featurewise_std_normalization = False,\n",
    "    samplewise_std_normalization = False,\n",
    "    rotation_range = 30,\n",
    "    shear_range = 0.4,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = False,\n",
    "    zca_whitening = False,\n",
    "    channel_shift_range = 0.0)\n",
    "\n",
    "# 計算特徵正規化所需的數量\n",
    "datagen.fit(x_train)\n",
    "x_IDG_train = x_train\n",
    "y_IDG_label = y_train\n",
    "\n",
    "#決定我要生成幾倍的資料量\n",
    "for e in range(4):\n",
    "    print('Data Gene epochs =',e)\n",
    "    batches=0\n",
    "    per_batch=32\n",
    "    #每次的batch_size生成數據\n",
    "    for x_batch,y_batch in datagen.flow(x_train,y_train,batch_size=32):\n",
    "        x_IDG_train = np.concatenate((x_IDG_train, x_batch), axis = 0)\n",
    "        y_IDG_label = np.concatenate((y_IDG_label, y_batch), axis = 0)\n",
    "        batches += 1\n",
    "        if batches >= len(train) / per_batch:\n",
    "        # 需要手動跳出迴圈\n",
    "            break\n",
    "print('Data Augment(x_IDG_train) total shape =',x_IDG_train.shape)\n",
    "print('Data Augment(y_IDG_label) total shape =',y_IDG_label.shape)\n",
    "print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_labels_predict(x_IDG_train,y_IDG_label, [], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正規化\n",
    "正規化對CNN模組在學習上有\"非常非常非常\"大的重要性，如果在沒有做正規化的情況下training model，那麼model學習的效率會非常低，幾乎學不起來。選擇除以255的原因在於，圖片上每個像素的值屆於0~255之間，除以255可以讓所有值屆於0~1之間。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "#x_train = x_train/255\n",
    "x_IDG_train = x_IDG_train /255\n",
    "x_valid = x_valid/255\n",
    "\n",
    "#print(\"\\t[Info] x_train: %s\" % (str(x_train.shape)))\n",
    "print(\"\\t[Info] x_IDG_train: %s\" % (str(x_IDG_train.shape)))\n",
    "print(\"\\t[Info] y_IDG_label: %s\" % (str(y_IDG_label.shape)))\n",
    "#x_train[0]\n",
    "x_IDG_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_labels_predict(x_IDG_train,y_IDG_label, [], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定義模組\n",
    "以下例子中，我用tensorflow架構了四層convolutions layer，並在每一層後面，都接上pool 2*2，做完pool要進入下一層之前，drop 25%神經元，讓模組在學習時，不會太容易overfitting。在CNN之後，我接上兩層的MLP，第一層 layer數量是512，第二層 layer數量是128，最後經過softmax分類成15類。(out put layer)<br>\n",
    "## drop\n",
    "drop在解決overfittimg時，是非常有用的方式，因為model在每次進入下一層之前，都遺失了一些訊號，那麼自然不可能過度學習啦!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "#sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "lr = 0.0001\n",
    "\n",
    "hidden1_neurons = 512\n",
    "hidden2_neurons = 256\n",
    "image_cnn_shape = (image_width//32) * (image_high//32)\n",
    "\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    xs = tf.placeholder(shape = [None, image_width, image_high, 3],\n",
    "                        dtype = tf.float32,\n",
    "                        name = 'xs')\n",
    "    ys = tf.placeholder(shape = [None, 15],\n",
    "                        dtype = tf.float32,\n",
    "                        name = 'ys')\n",
    "    keep_prob = tf.placeholder(dtype = tf.float32,\n",
    "                              name = 'keep_prob')\n",
    "## conv1 layer ##\n",
    "with tf.variable_scope('conv1'):\n",
    "    conv1_1 = tf.layers.conv2d(inputs=xs, filters=32, strides=(1, 1), kernel_size=[3,3], padding=\"same\",\n",
    "                               activation=tf.nn.relu)\n",
    "    conv1_2 = tf.layers.conv2d(inputs=conv1_1, filters=32, strides=(1, 1), kernel_size=[3,3], padding=\"same\",\n",
    "                               activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1_2, strides=2, pool_size=[2,2])\n",
    "\n",
    "## conv2 layer ##\n",
    "with tf.variable_scope('conv2'):\n",
    "    conv2_1 = tf.layers.conv2d(inputs=pool1, filters=64, strides=(1, 1), kernel_size=[3,3], padding=\"same\",\n",
    "                               activation=tf.nn.relu)\n",
    "    conv2_2 = tf.layers.conv2d(inputs=conv2_1, filters=64, strides=(1, 1), kernel_size=[3,3], padding=\"same\",\n",
    "                               activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2_2, strides=2, pool_size=[2,2])\n",
    "\n",
    "# conv3 layer ##\n",
    "with tf.variable_scope('conv3'):\n",
    "    conv3_1 = tf.layers.conv2d(inputs=pool2, filters=128, strides=(1, 1), kernel_size=[3,3], padding=\"same\",\n",
    "                               activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3_1, strides=2, pool_size=[2,2])\n",
    "\n",
    "# conv4 layer ##\n",
    "with tf.variable_scope('conv4'):\n",
    "    conv4_1 = tf.layers.conv2d(inputs=pool3, filters=256, strides=(1, 1), kernel_size=[3,3], padding=\"same\",\n",
    "                               activation=tf.nn.relu)\n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv4_1, strides=2, pool_size=[2,2])\n",
    "\n",
    "# conv5 layer ##\n",
    "with tf.variable_scope('conv5'):\n",
    "    conv5_1 = tf.layers.conv2d(inputs=pool4, filters=512, strides=(1, 1), kernel_size=[3,3], padding=\"same\",\n",
    "                               activation=tf.nn.relu)\n",
    "    pool5 = tf.layers.max_pooling2d(inputs=conv5_1, strides=2, pool_size=[2,2])\n",
    "\n",
    "with tf.variable_scope('hidden_layer'):\n",
    "    pool5_flat = tf.reshape(pool5, [-1, image_cnn_shape*512])\n",
    "    hidden_1 = tf.layers.dense(inputs=pool5_flat, units=512, activation=tf.nn.relu)\n",
    "    hidden_2 = tf.layers.dense(inputs=hidden_1, units=256, activation=tf.nn.relu)\n",
    "    \n",
    "with tf.variable_scope('output_layer'):\n",
    "    output = tf.layers.dense(inputs=hidden_1, units=15, activation=tf.nn.relu)\n",
    "    pre = tf.nn.softmax(output)\n",
    "\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=ys))\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(output),1), tf.argmax(ys,1)) #如果答案對則回傳true\n",
    "    compute_acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #將回傳的true/false轉乘1/0並計算平均(計算正確率)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    #使用adam做optimization最小化loss funciotn(不斷取微分並逼近local min)\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loss_list, valid_loss_list = [], []\n",
    "train_acc_list, valid_acc_list = [], []\n",
    "\n",
    "sess = tf.Session()\n",
    "#tf.reset_default_graph()\n",
    "#sess = tf.InteractiveSession()\n",
    "# important step\n",
    "# tf.initialize_all_variables() no long valid from\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in tqdm(range(epochs)):\n",
    "    # get batch\n",
    "    total_batch = int(np.floor(len(x_IDG_train) / batch_size)) # just drop out last few samples...\n",
    "    \n",
    "    train_loss_collector, train_acc_collector = [], []\n",
    "    for j in np.arange(total_batch):\n",
    "        batch_idx_start = j * batch_size\n",
    "        batch_idx_stop = (j+1) * batch_size\n",
    "\n",
    "        x_batch = x_IDG_train[batch_idx_start : batch_idx_stop]\n",
    "        y_batch = y_IDG_label[batch_idx_start : batch_idx_stop]\n",
    "        \n",
    "        this_loss, this_acc, _ = sess.run([loss, compute_acc, train_step], feed_dict = {xs: x_batch, ys: y_batch, keep_prob: 1})\n",
    "        train_loss_collector.append(this_loss)\n",
    "        train_acc_collector.append(this_acc)\n",
    "            \n",
    "    # do validation at the end of each epoch\n",
    "    valid_total_batch = int(np.floor(len(x_valid) / batch_size))\n",
    "    valid_loss_collector, valid_acc_collector = [], []\n",
    "    for j in np.arange(valid_total_batch):\n",
    "        batch_idx_start = j * batch_size\n",
    "        batch_idx_stop = (j+1) * batch_size\n",
    "\n",
    "        x_batch = x_valid[batch_idx_start : batch_idx_stop]\n",
    "        y_batch = y_valid[batch_idx_start : batch_idx_stop]\n",
    "        \n",
    "        this_acc, this_loss = sess.run([compute_acc, loss], feed_dict = {xs: x_batch, ys : y_batch, keep_prob: 1})\n",
    "        valid_acc_collector.append(this_acc)\n",
    "        valid_loss_collector.append(this_loss)\n",
    "    \n",
    "    valid_loss_list.append(np.mean(valid_loss_collector))\n",
    "    valid_acc_list.append(np.mean(valid_acc_collector))\n",
    "    train_loss_list.append(np.mean(train_loss_collector))\n",
    "    train_acc_list.append(np.mean(train_acc_collector))\n",
    "\n",
    "    # at the end of each epoch, shuffle the data\n",
    "    x_IDG_train, y_IDG_label = shuffle(x_IDG_train, y_IDG_label)\n",
    "\n",
    "# At the end of the training, do testing set\n",
    "#result = sess.run(pre, feed_dict={xs: x_valid, ys: y_valid, keep_prob: 1})\n",
    "print('--- training done ---')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "model_path = \"model_cnn/model.ckpt\"\n",
    "save_path = saver.save(sess, model_path)\n",
    "\n",
    "print(\"--- save done ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy: %.2f' % valid_acc_list[len(valid_acc_list)-1])\n",
    "#--------------------------------------plot---------------------------------------------\n",
    "print(\"loss\")\n",
    "plt.plot(np.arange(len(train_loss_list)), train_loss_list, 'b', label = 'train')\n",
    "plt.plot(np.arange(len(valid_loss_list)), valid_loss_list, 'r', label = 'valid')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"accuracy\")\n",
    "plt.plot(np.arange(len(train_acc_list)), train_acc_list, 'b', label = 'train')\n",
    "plt.plot(np.arange(len(valid_acc_list)), valid_acc_list, 'r', label = 'valid')\n",
    "plt.legend(loc = 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混淆矩陣\n",
    "我們可以透過混淆矩陣，觀察分類錯誤的情況。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "#Y_pred = model.predict(x_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(result, axis = 1)\n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_valid, axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/result.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 後言：\n",
    "在建立model的過程中，一開始用兩層的convolution作為model，這時觀察會發現，圖片像素越少(圖片越小)，model準確率變高，然而這樣辨識率的極限大約(25%左右)，再想要獲得更好的辨識率，勢必需要調高圖片的像素。\n",
    "## 關於圖片大小選用\n",
    "圖片越大，model能學習的資源越多，因此為了提取更精準的特徵，勢必也要加深CNN捲積的部分。\n",
    "## train loss Nan\n",
    "在加深捲積層時，發現model有學不起來來的現象，在第1個epochs時，train loss極劇下降到接近0，之後就不會在變動了。這時觀察混淆矩陣會發現模組將大部分的資料，都分類到同個分類，也就是說 模組過於執著。上網查資料後發現，最常見的原因是學習率太高，導致模組「顽固」認為數據屬於錯誤的類別，而正確的類別機率為0(小數點下溢出)，這樣用交叉熵就會算出無窮大的損失函數。一旦出現這種情況，無窮大對參數求值就會變成NaN，之後整個網路的參數都變成NaN了。<b>為了解決這個問題，調降learn rate有效降低這個現象。</b>\n",
    "<img src=\"img/lossNan.png\"/>\n",
    "參考資料：https://www.zhihu.com/question/62441748\n",
    "## 捲積層大小\n",
    "這會影響一個捲積層視野的大小，為了讓filter看到更大片的圖形，一開始我採用5*5的filter，發現model學習的結果不好，參考VGG-16、VGG-19的論文結論，改成採用兩層3*3的filter。<br>\n",
    "原因有以下幾點:<br>\n",
    "1：3x3是最小的能夠捕獲上下左右的最小單位。 <br>\n",
    "2：兩個3x3的捲積層的視野是5x5；三個3x3的視野是7x7，可以替代大的filter尺寸。 <br>\n",
    "<img src=\"img/filter.png\" width=\"400px\"/>\n",
    "<center>最左上角的像素對3x3、5x5的視野範圍</center>\n",
    "<img src=\"img/filter2.png\" width=\"400px\"/>\n",
    "<center>紅色的區塊是3x3兩層的範圍</center><br>\n",
    "可以看出對左上角(黃色)的像素來說，3x3兩層與5x5的範圍一致<br>\n",
    "3：多個3x3的捲積層比一个大尺寸filter捲積層有更多的非線性(激發函數)，使得判决函数更加具有判决性。<br>\n",
    "4：多個3x3的捲積層比一个大尺寸的filter有更少的参数，假设捲積層的输入和输出的特征圖大小相同為C，那麼三個3x3的捲積層参數個數為:3x（3x3xCxC）=27CC；一個7x7的捲積層參數為49CC；所以可以把三個3x3的filter看成是一個7x7filter的分解，又有更多的非線性(激發函數)。\n",
    "\n",
    "參考資料：https://blog.csdn.net/u011440696/article/details/77756776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
